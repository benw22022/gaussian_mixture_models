{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "conf = OmegaConf.load('../config/features.yaml')\n",
    "dataset = pd.read_csv('../data/mumu-mc.MGPy8EG_lrsm132_mumuchannel_WRWL_4.50_0.55_0.020_0.000_.EVNT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformation onto latent space\n",
    "def smoothing_function(u: np.ndarray, alpha: float=4, beta: float=3, gamma: float=1) -> np.ndarray:\n",
    "    \n",
    "    q = 1 / (1 + np.exp(alpha * (u - beta)) - gamma) * 1 / (1 + np.exp(-alpha * (u + beta)) - gamma)\n",
    "    \n",
    "    return q\n",
    "\n",
    "def get_cumalative_distribution(data: np.ndarray, weights: np.ndarray=None, npoints: int=50, lower_lim: float=None, upper_lim: float=None) -> np.ndarray:\n",
    "    \n",
    "    if lower_lim is None:\n",
    "        lower_lim = np.amin(data)\n",
    "    if upper_lim is None:\n",
    "        upper_lim = np.amax(data)\n",
    "    if weights is None:\n",
    "        weights = np.ones_like(data, weights, npoints, lower_lim, upper_lim)\n",
    "    \n",
    "    ax_scan_points = np.linspace(lower_lim, upper_lim, npoints + 1)\n",
    "    \n",
    "    data_cdf = []\n",
    "    for point in ax_scan_points :\n",
    "        data_cdf.append(np.sum([w for x,w in zip(data, weights) if x < point]))\n",
    "        \n",
    "    data_cdf = np.array(data_cdf)\n",
    "    \n",
    "    return data_cdf\n",
    "\n",
    "def transform_onto_latent_space(data: np.ndarray, conf: OmegaConf, weights: np.ndarray=None):\n",
    "    \n",
    "    xmin = np.amin(data)\n",
    "    xmax = np.amax(data)\n",
    "    x_scan_points = np.linspace(xmin, xmax, 1 + conf.n_axis_points)\n",
    "\n",
    "    umin = conf.smooth_space_limits[0]\n",
    "    umax = conf.smooth_space_limits[1]\n",
    "    udiv = conf.smooth_space_division\n",
    "    \n",
    "    data_cdf = get_cumalative_distribution(data, npoints=conf.n_axis_points, weights=weights)\n",
    "    constant_cdf = (x_scan_points - xmin) / (xmax - xmin)\n",
    "    combined_cdf = conf.data_frac_constant * constant_cdf + (1 - conf.data_frac_constant) * data_cdf\n",
    "    \n",
    "    latent_space_x = np.linspace(umin, umax, 1 + int(2 * umax / udiv))\n",
    "    smooth_space_y = smoothing_function(latent_space_x, conf.alpha, conf.beta, conf.gamma)\n",
    "    \n",
    "    smooth_space_cdf = np.array([np.sum(smooth_space_y[:i+1]) for i in range(len(smooth_space_y))])\n",
    "    smooth_space_cdf /= smooth_space_cdf[-1]\n",
    "    smooth_space_cdf[0] = 0.\n",
    "    \n",
    "    constant_cdf    = (latent_space_x + umax) / (2 * umax)\n",
    "    latent_space_cdf = conf.gauss_frac_constant * constant_cdf + (1 - conf.gauss_frac_constant) * smooth_space_cdf\n",
    "\n",
    "    A_to_z = lambda A : np.interp(A, x_scan_points, combined_cdf)     # x -> x_CDF\n",
    "    z_to_A = lambda z : np.interp(z, combined_cdf  , x_scan_points)   # x_CDF -> x\n",
    "\n",
    "    z_to_g = lambda z : np.interp(z, latent_space_cdf, latent_space_x  )  # u_CDF -> u\n",
    "    g_to_z = lambda g : np.interp(g, latent_space_x  , latent_space_cdf)  # u -> u_CDF\n",
    "\n",
    "    A_to_g = lambda A : z_to_g(A_to_z(A))  # x -> u\n",
    "    g_to_A = lambda g : z_to_A(g_to_z(g))  # u -> x\n",
    "    \n",
    "    return A_to_g, g_to_A\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot delta_phi_jj\n",
    "delta_phi_jj = dataset['delta_phi_jj']\n",
    "weights = dataset['weight']\n",
    "\n",
    "x_to_latent_space, latent_space_to_x = transform_onto_latent_space(delta_phi_jj, conf, weights=weights)\n",
    "\n",
    "delta_phi_jj_trans = x_to_latent_space(delta_phi_jj)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6));\n",
    "ax1.hist(dataset['delta_phi_jj'], 24, histtype='step', density=False);\n",
    "ax2.hist(delta_phi_jj_trans, 25, histtype='step', density=False);\n",
    "ax1.set_xlabel(r\"$\\Delta\\phi_{jj}$\");\n",
    "ax2.set_xlabel(r\"$\\Delta\\phi_{jj}$\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observable delta_phi_jj closure is 0.99986 +- 0.00151     (should be 1 +- 0)\n"
     ]
    }
   ],
   "source": [
    "# Check closure\n",
    "\n",
    "delta_phi_jj_trans_back = latent_space_to_x(delta_phi_jj_trans)\n",
    "\n",
    "ratio = (delta_phi_jj_trans_back / delta_phi_jj).transpose()\n",
    "print(f\"Observable delta_phi_jj closure is {np.mean(ratio):.5f} +- {np.std(ratio):.5f}     (should be 1 +- 0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create GMM \n",
    "import tensorflow as tf\n",
    "from   keras.activations import softplus\n",
    "from   keras.layers      import BatchNormalization, Dense, Dropout, Input, LeakyReLU, Concatenate, Lambda, Reshape, Softmax\n",
    "from   keras.models      import Model\n",
    "from   keras.optimizers  import Adam, SGD, Adadelta\n",
    "from   keras.callbacks   import Callback, EarlyStopping\n",
    "import keras.backend     as     K\n",
    "\n",
    "def custom_weight_init_initial (shape, dtype=None, g=0.2) :\n",
    "    \"\"\"Keras: custom weight initialiser function for leaky relu layer with gradient g (first layer in network)\"\"\"\n",
    "    limit = 4. / np.sqrt(shape[0]) / (1 + g)\n",
    "    return K.random_uniform(shape, -limit, limit, dtype=dtype)\n",
    "\n",
    "def custom_weight_init_hidden (shape, dtype=None, g=0.2) :\n",
    "    \"\"\"Keras: custom weight initialiser function for leaky relu layer with gradient g (not first layer in network)\"\"\"\n",
    "    limit = 3. / np.sqrt(shape[0]) / (1 + g)\n",
    "    return K.random_uniform(shape, -limit, limit, dtype=dtype)\n",
    "\n",
    "def add_gauss_mean_offsets (x, num_gauss, offset_min, offset_max) :\n",
    "    \"\"\"TF method: for input x of size [?, num_gauss], add evenly spaced offsets between [offset_min, offset_max]\"\"\"\n",
    "    c = tf.convert_to_tensor([offset_min + (offset_max-offset_min)*i/(num_gauss-1.) for i in range(num_gauss)])\n",
    "    return x + c    \n",
    "\n",
    "def set_initial_gauss_sigmas (x, num_gauss, offset_min, offset_max, gauss_width_factor) :\n",
    "    \"\"\"TF method: for input x of size [?, num_gauss], add a constant factor which sets initial Gaussian widths as gauss_width_factor * (offset_max-offset_min) / num_gauss\n",
    "       - to be applied before a Softmax function, so offset addition is performed in a logarithmic basis\"\"\"\n",
    "    target_width = gauss_width_factor * float(offset_max - offset_min) / num_gauss\n",
    "    offset       = float(np.log(np.exp(target_width) - 1))\n",
    "    c = tf.convert_to_tensor([offset for i in range(num_gauss)])\n",
    "    return x + c\n",
    "\n",
    "def add_epsilon_to_gauss_sigmas (x, num_gauss, epsilon=1e-4) :\n",
    "    \"\"\"TF method: for input x of size [?, num_gauss], add epsilon to every value\"\"\"\n",
    "    c = tf.convert_to_tensor([float(epsilon) for i in range(num_gauss)])\n",
    "    return x + c\n",
    "\n",
    "def add_gauss_fraction_offsets (x, num_gauss, const_frac=0.2) :\n",
    "    \"\"\"TF method: for input x of size [?, num_gauss], where x is a multinomial(num_gauss) probability distribution, add a constant term to prevent probabilities going to 0\"\"\"\n",
    "    c = tf.convert_to_tensor([1./num_gauss for i in range(num_gauss)])\n",
    "    return (1.-const_frac)*x + const_frac*c\n",
    "\n",
    "def K_gauss_prob (x, mean, sigma) :\n",
    "    \"\"\"return the Gaussian probability density for datapoints x\"\"\"\n",
    "    prob = K.exp(-0.5*(x - mean)*(x - mean)/(sigma*sigma)) / K.sqrt(2*np.pi*sigma*sigma)\n",
    "    return prob\n",
    "\n",
    "def K_datapoint_likelihood (x, num_gauss, gauss_fracs, gauss_means, gauss_sigmas) :\n",
    "    \"\"\"Keras: return the probability density for datapoints x as described by the Gaussian mixture model\"\"\"\n",
    "    prob = 0.\n",
    "    x = x[:,0]\n",
    "    for i in range(num_gauss) :\n",
    "        prob = prob + gauss_fracs[:,i] * K_gauss_prob(x, gauss_means[:,i], gauss_sigmas[:,i])\n",
    "    return prob\n",
    "\n",
    "def K_datapoint_log_likelihood (x, num_gauss, gauss_fracs, gauss_means, gauss_sigmas) :\n",
    "    \"\"\"Keras: return the log probability density for datapoints x as described by the Gaussian mixture model\"\"\"\n",
    "    return K.log(K_datapoint_likelihood(x, num_gauss, gauss_fracs, gauss_means, gauss_sigmas))\n",
    "\n",
    "def K_dataset_log_likelihood (x, params, num_gauss) :\n",
    "    \"\"\"Keras: return the log probability density for datapoints x as described by the Gaussian mixture model\"\"\"\n",
    "    gauss_fracs, gauss_means, gauss_sigmas = params[:,:num_gauss], params[:,num_gauss:2*num_gauss], params[:,2*num_gauss:3*num_gauss]\n",
    "    return K_datapoint_log_likelihood(x, num_gauss, gauss_fracs, gauss_means, gauss_sigmas)\n",
    "\n",
    "def GMM(conf: OmegaConf) -> tf.keras.Model:\n",
    "    \n",
    "    N1     = conf.A1 + conf.A2 * conf.n_external_parameters\n",
    "    N2     = conf.B1 + conf.B2 * conf.n_observables if conf.n_observables > 0 else 0\n",
    "    \n",
    "    conditions_input  = Input((conf.n_external_parameters,))\n",
    "    model_conditions  = conditions_input\n",
    "    model_conditions  = Dense(N1, kernel_initializer=custom_weight_init_initial, bias_initializer='zeros', activation='relu')(model_conditions) \n",
    "    if conf.use_leaky_relu : model_conditions = LeakyReLU (0.2)      (model_conditions)\n",
    "    if conf.batch_norm     : model_conditions = BatchNormalization() (model_conditions)\n",
    "    if conf.dropout > 0.   : model_conditions = Dropout(conf.dropout)     (model_conditions)\n",
    "    \n",
    "    #\n",
    "    #  If they exist, create an input layer for other input observables\n",
    "    #  -  if configured, add a layer which transforms these inputs onto the given domain\n",
    "    #  -  add a layer to process just these inputs\n",
    "    #  -  concatenate the resulting hidden layer with that from the external parameter dependence\n",
    "    #  If they don't exist, skip this step\n",
    "    #\n",
    "    \n",
    "    if conf.n_observables > 0 :\n",
    "        observables_input = Input((conf.n_observables,))\n",
    "        model_observables = observables_input\n",
    "        model_observables = Dense(N2, kernel_initializer=custom_weight_init_initial, bias_initializer='zeros', activation='relu')(model_observables)    \n",
    "        if conf.use_leaky_relu : model_observables = LeakyReLU(0.2)       (model_observables)\n",
    "        if conf.batch_norm     : model_observables = BatchNormalization() (model_observables)\n",
    "        if conf.dropout > 0.   : model_observables = Dropout(conf.dropout)     (model_observables)\n",
    "        model             = Concatenate()([model_conditions, model_observables])\n",
    "    else :\n",
    "        model = model_conditions\n",
    "        \n",
    "    for c in range(conf.C) :\n",
    "        model = Dense (N1 + N2, kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation='relu')(model)\n",
    "        if conf.use_leaky_relu : model = LeakyReLU (0.2)      (model)\n",
    "        if conf.batch_norm     : model = BatchNormalization() (model)\n",
    "        if conf.dropout > 0.   : model = Dropout(conf.dropout)     (model)\n",
    "    \n",
    "    gauss_means     = Dense (conf.D2 * conf.num_gaussians, kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation='relu')(model)\n",
    "    if conf.use_leaky_relu : gauss_means = LeakyReLU (0.2)      (gauss_means)\n",
    "    if conf.batch_norm     : gauss_means = BatchNormalization() (gauss_means)\n",
    "    if conf.dropout > 0.   : gauss_means = Dropout(conf.dropout)     (gauss_means)\n",
    "    gauss_means = Dense (conf.num_gaussians, kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation=\"linear\")(gauss_means)\n",
    "    gauss_means = Lambda(lambda x : conf.gauss_mean_scale * x)(gauss_means)\n",
    "    gauss_means = Lambda(lambda x : add_gauss_mean_offsets(x, conf.num_gaussians, conf.range_min, conf.range_max))(gauss_means)\n",
    "    \n",
    "    gauss_sigmas       = Dense (conf.D2 * conf.num_gaussians   , kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation='relu')(model)\n",
    "    if conf.use_leaky_relu : gauss_sigmas = LeakyReLU (0.2)      (gauss_sigmas)\n",
    "    if conf.batch_norm     : gauss_sigmas = BatchNormalization() (gauss_sigmas)\n",
    "    if conf.dropout > 0.   : gauss_sigmas = Dropout(conf.dropout)     (gauss_sigmas)\n",
    "    gauss_sigmas = Dense (conf.num_gaussians     , kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation='relu')(gauss_sigmas)\n",
    "    gauss_sigmas = Lambda (lambda x : conf.gauss_sigma_scale * x )                                                                (gauss_sigmas)\n",
    "    gauss_sigmas = Lambda (lambda x : set_initial_gauss_sigmas(x, conf.num_gaussians, conf.range_min, conf.range_max, conf.gauss_width_factor))(gauss_sigmas)\n",
    "    gauss_sigmas = Lambda (lambda x : K.log(1. + K.exp(x)))                                                                (gauss_sigmas)\n",
    "    gauss_sigmas = Lambda (lambda x : add_epsilon_to_gauss_sigmas(x, conf.num_gaussians))                                       (gauss_sigmas)\n",
    "    \n",
    "    \n",
    "    gauss_fractions = Dense(conf.D2 * conf.num_gaussians , kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation='relu')(model)\n",
    "    if conf.use_leaky_relu : gauss_fractions = LeakyReLU (0.2)      (gauss_fractions)\n",
    "    if conf.batch_norm     : gauss_fractions = BatchNormalization() (gauss_fractions)\n",
    "    if conf.dropout > 0.   : gauss_fractions = Dropout(conf.dropout)     (gauss_fractions)\n",
    "    gauss_fractions = Dense(conf.num_gaussians, kernel_initializer=custom_weight_init_hidden, bias_initializer='zeros', activation=\"linear\")(gauss_fractions)\n",
    "    gauss_fractions = Lambda(lambda x : conf.gauss_frac_scale * x)                                                    (gauss_fractions)\n",
    "    gauss_fractions = Softmax()                                                                                (gauss_fractions)\n",
    "    gauss_fractions = Lambda(lambda x : add_gauss_fraction_offsets(x, conf.num_gaussians, conf.min_gauss_amplitude_frac))(gauss_fractions)\n",
    "    \n",
    "    \n",
    "    model = Concatenate()([gauss_fractions, gauss_means, gauss_sigmas])\n",
    "    if conf.n_observables > 0 : model = Model ([conditions_input, observables_input], model, name='GMM')\n",
    "    else                      : model = Model (conditions_input, model, name='GMM')\n",
    "    \n",
    "    loss_function = lambda y_true, y_pred : -1. * K_dataset_log_likelihood(y_true, y_pred, conf.num_gaussians)\n",
    "    #loss_function = lambda y_true, y_pred : K_dataset_PlogP (y_true, y_pred, num_gaussians)\n",
    "    if   conf.optimiser.lower() == \"sgd\"      : model.compile(loss=loss_function, optimizer=SGD     (learning_rate=conf.learning_rate))    \n",
    "    elif conf.optimiser.lower() == \"adadelta\" : model.compile(loss=loss_function, optimizer=Adadelta(learning_rate=conf.learning_rate))    \n",
    "    elif conf.optimiser.lower() == \"adam\"     : model.compile(loss=loss_function, optimizer=Adam    (learning_rate=conf.learning_rate))   \n",
    "    else : raise ValueError(f\"Optimiser '{conf.optimiser}' not recognised\") \n",
    "    \n",
    "    return model, (conf.n_external_parameters, conf.n_observables, conf.num_gaussians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2052/2052 [==============================] - ETA: 0s - loss: 2.9744e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 102s 45ms/step - loss: 2.9744e-04 - val_loss: nan\n",
      "Epoch 2/30\n",
      "2052/2052 [==============================] - ETA: 0s - loss: 2.5117e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 94s 46ms/step - loss: 2.5117e-04 - val_loss: 0.0010\n",
      "Epoch 3/30\n",
      "2051/2052 [============================>.] - ETA: 0s - loss: 1.6836e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 93s 45ms/step - loss: 1.6836e-04 - val_loss: 5.9017e-04\n",
      "Epoch 4/30\n",
      "2052/2052 [==============================] - ETA: 0s - loss: 1.5403e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 89s 43ms/step - loss: 1.5403e-04 - val_loss: 3.1315e-04\n",
      "Epoch 5/30\n",
      "2052/2052 [==============================] - ETA: 0s - loss: 1.4312e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 88s 43ms/step - loss: 1.4312e-04 - val_loss: 4.6483e-04\n",
      "Epoch 6/30\n",
      "2052/2052 [==============================] - ETA: 0s - loss: 1.3725e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 95s 46ms/step - loss: 1.3725e-04 - val_loss: 3.0987e-04\n",
      "Epoch 7/30\n",
      "2052/2052 [==============================] - ETA: 0s - loss: 1.3329e-04WARNING:tensorflow:`evaluate()` received a value for `sample_weight`, but `weighted_metrics` were not provided.  Did you mean to pass metrics to `weighted_metrics` in `compile()`?  If this is intentional you can pass `weighted_metrics=[]` to `compile()` in order to silence this warning.\n",
      "2052/2052 [==============================] - 94s 46ms/step - loss: 1.3329e-04 - val_loss: 1.9472e-04\n",
      "Epoch 8/30\n",
      " 180/2052 [=>............................] - ETA: 1:28 - loss: 1.3292e-04"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_conf = OmegaConf.load('../config/features/delta_phi_jj.yaml')\n",
    "\n",
    "model, params = GMM(model_conf)\n",
    "\n",
    "y = dataset['delta_phi_jj']\n",
    "weights = dataset['weight']\n",
    "\n",
    "x = np.stack([4.5, 0.55, 0.02, 0.0] for _ in range(len(y)));\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state=42);\n",
    "\n",
    "history = model.fit(x, y, sample_weight=weights, validation_split=0.1, epochs=30, shuffle=True, batch_size=4);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss vs epochs\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(history['loss'], label='Train')\n",
    "ax.plot(history['val_loss'], label='Val')\n",
    "ax.set_xlabel(\"Epochs\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('scikit-hep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b817e921d488b1f0f8243d1aee10aa92224a8caad85930bc5eacaa9bc2a43258"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
